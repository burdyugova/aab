{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mse(y, y_pred):\n",
    "    err = np.mean((y - y_pred)**2)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1\n",
    "Подберите скорость обучения (alpha) и количество итераций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [ 1,  1,  2,  1,  3,  0,  5, 10,  1,  2]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "              [1, 1, 2, 1, 3, 0, 5, 10, 1, 2]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[45, 55, 50, 59, 65, 35, 75, 80, 50, 60]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [45, 55, 50, 59, 65, 35, 75, 80, 50, 60]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1. , 0.5]), 0.0001)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = X.shape[1]\n",
    "alpha = 1e-4\n",
    "W = np.array([1, 0.5])\n",
    "W, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1.01102 0.534  ] 3173.15\n",
      "100 [2.02168794 3.452835  ] 2207.6942101483005\n",
      "200 [2.88306663 5.58962851] 1670.7027004086372\n",
      "300 [3.63289519 7.14848061] 1368.0832412796256\n",
      "400 [4.29908617 8.28027926] 1193.7493344933293\n",
      "500 [4.90228732 9.09657298] 1089.714750358689\n",
      "600 [5.45777535 9.67982684] 1024.2828984889416\n",
      "700 [ 5.97685612 10.0910047 ] 980.1260644155933\n",
      "800 [ 6.46789973 10.37517467] 947.770026039189\n",
      "900 [ 6.93710574 10.56565326] 922.0330206910179\n"
     ]
    }
   ],
   "source": [
    "W = np.array([1, 0.5])\n",
    "\n",
    "for i in range(1000):\n",
    "    y_pred = np.dot(W, X)\n",
    "    err = calc_mse(y, y_pred)\n",
    "    for j in range(W.shape[0]):\n",
    "        W[j] -= alpha * (1/n * 2 * np.sum(X[j] * (y_pred - y)))\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(i, W, err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degrad_iter(alpha):\n",
    "    W = np.array([1, 0.5])\n",
    "    delta = 1e-4\n",
    "    err_prev = 0\n",
    "    i = 0\n",
    "\n",
    "    while True:\n",
    "        y_pred = np.dot(W, X)\n",
    "        err = calc_mse(y, y_pred)\n",
    "        for j in range(W.shape[0]):\n",
    "            W[j] -= alpha * (1/n * 2 * np.sum(X[j] * (y_pred - y)))\n",
    "\n",
    "        if abs(err_prev - err) <= delta:\n",
    "            return(i, W, err)\n",
    "        else:\n",
    "            err_prev = err\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Лучшая скорость обучения alpha: 0.0631 \n",
      "Количество итераций 105\n"
     ]
    }
   ],
   "source": [
    "alpha = 1e-4\n",
    "step_cnt = 1\n",
    "factor = 20\n",
    "\n",
    "j_prv = np.inf\n",
    "i = 0\n",
    "\n",
    "while True:\n",
    "    j, W, err = degrad_iter(alpha + alpha*factor*i)\n",
    "    # print(\"П1 Шаг: {}\\tИтераций: {}\\talpha: {:.4f}\\tW: {}\\terr: {}\".format(step_cnt, j, alpha + alpha*factor*i, W, err))\n",
    "    step_cnt += 1\n",
    "    \n",
    "    if j_prv < j:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "        j_prv = j\n",
    "\n",
    "afd = alpha + alpha*factor*i\n",
    "j_prv = np.inf\n",
    "i = 0\n",
    "print()\n",
    "\n",
    "while True:\n",
    "    j, W, err = degrad_iter(afd - alpha*i)\n",
    "    # print(\"П2 Шаг: {}\\tИтераций: {}\\talpha: {:.4f}\\tW: {}\\terr: {}\".format(step_cnt, j, afd - alpha*i, W, err))\n",
    "    step_cnt += 1\n",
    "    \n",
    "    if j_prv < j:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "        j_prv = j   \n",
    "\n",
    "print(\"\\nЛучшая скорость обучения alpha: {:.4f} \\nКоличество итераций {}\".format((afd - alpha*(i-1)), j_prv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2\n",
    "В этом коде мы избавляемся от итераций по весам, но тут есть ошибка, исправьте ее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1.04502 0.54502] 3173.15\n",
      "100 [4.71884428 4.21884428] 1795.372786768742\n",
      "200 [7.1402917 6.6402917] 1196.8339637692059\n",
      "300 [8.73628737 8.23628737] 936.8146230533869\n",
      "400 [9.78822107 9.28822107] 823.8561064989115\n",
      "500 [10.48155912  9.98155912] 774.7842704306371\n",
      "600 [10.93854386 10.43854386] 753.4663108064917\n",
      "700 [11.23974622 10.73974622] 744.2052878053473\n",
      "800 [11.43827114 10.93827114] 740.1820816195831\n",
      "900 [11.56912052 11.06912052] 738.4343062376228\n"
     ]
    }
   ],
   "source": [
    "W = np.array([1, 0.5])\n",
    "\n",
    "for i in range(1000):\n",
    "    y_pred = np.dot(W, X)\n",
    "    err = calc_mse(y, y_pred)\n",
    "    '''for ii in range(W.shape[0]):\n",
    "        W[ii] -= alpha * (1/n * 2 * np.sum(X[ii] * (y_pred - y)))'''\n",
    "    W -= (alpha * (1/n * 2 * np.sum(X * (y_pred - y))))\n",
    "    if i % 100 == 0:\n",
    "        print(i, W, err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1.01102 0.534  ] 3173.15\n",
      "100 [2.02168794 3.452835  ] 2207.6942101483005\n",
      "200 [2.88306663 5.58962851] 1670.7027004086372\n",
      "300 [3.63289519 7.14848061] 1368.0832412796258\n",
      "400 [4.29908617 8.28027926] 1193.7493344933293\n",
      "500 [4.90228732 9.09657298] 1089.714750358689\n",
      "600 [5.45777535 9.67982684] 1024.2828984889416\n",
      "700 [ 5.97685612 10.0910047 ] 980.1260644155933\n",
      "800 [ 6.46789973 10.37517467] 947.770026039189\n",
      "900 [ 6.93710574 10.56565326] 922.0330206910179\n"
     ]
    }
   ],
   "source": [
    "W = np.array([1, 0.5])\n",
    "\n",
    "for i in range(1000):\n",
    "    y_pred = np.dot(W, X)\n",
    "    err = calc_mse(y, y_pred)\n",
    "    W -= alpha * 1/n * 2 * (X @ (y_pred - y))\n",
    "    if i % 100 == 0:\n",
    "        print(i, W, err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание № 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вместо того, чтобы задавать количество итераций, задайте условие остановки алгоритма - когда ошибка за итерацию\n",
    "начинает изменяться ниже определенного порога (упрощенный аналог параметра tol в линейной регрессии в sklearn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1.01102 0.534  ] 3173.15\n",
      "1000 [ 7.38906894 10.68706909] 900.0794345405571\n",
      "2000 [11.41239979 10.49676806] 735.6901949760081\n",
      "3000 [14.95426267  9.86968976] 606.1685205795002\n",
      "4000 [18.14222899  9.28232201] 500.9761357445739\n",
      "5000 [21.01515239  8.75187884] 415.5353314487194\n",
      "6000 [23.60433677  8.27376927] 346.13740897688945\n",
      "7000 [25.93781343  7.8428751 ] 289.770059830036\n",
      "8000 [28.04083646  7.45453582] 243.9865848111653\n",
      "9000 [29.93616542  7.10454883] 206.79969175109696\n",
      "10000 [31.64431213  6.78912647] 176.5952344683994\n",
      "11000 [33.18376267  6.50485515] 152.06214862364686\n",
      "12000 [34.57117743  6.2486584 ] 132.13554324111018\n",
      "13000 [35.82157143  6.01776359] 115.95047771025502\n",
      "14000 [36.94847681  5.80967189] 102.8044178967979\n",
      "15000 [37.96408928  5.62213128] 92.12674172121734\n",
      "16000 [38.8794001   5.45311213] 83.45397055415961\n",
      "17000 [39.70431503  5.30078528] 76.40965131472\n",
      "18000 [40.44776156  5.16350219] 70.68801602753328\n",
      "19000 [41.11778548  5.03977715] 66.04070956017475\n",
      "20000 [41.72163799  4.92827116] 62.26600944080188\n",
      "21000 [42.26585417  4.82777748] 59.200069827981494\n",
      "22000 [42.75632369  4.73720853] 56.709809565657416\n",
      "23000 [43.19835455  4.65558415] 54.68713561990321\n",
      "24000 [43.59673054  4.58202098] 53.04425115809348\n",
      "25000 [43.95576302  4.51572289] 51.7098446114915\n",
      "26000 [44.27933753  4.45597238] 50.62599430247339\n",
      "27000 [44.5709559   4.40212281] 49.74565427765066\n",
      "28000 [44.8337741   4.35359142] 49.03061221616227\n",
      "29000 [45.07063644  4.30985298] 48.449830773446266\n",
      "30000 [45.28410632  4.27043414] 47.97810036432719\n",
      "31000 [45.47649395  4.23490829] 47.594944907694035\n",
      "32000 [45.64988143  4.20289096] 47.283733035171785\n",
      "33000 [45.8061452   4.17403566] 47.030956184621665\n",
      "34000 [45.9469764  4.1480301] 46.825642243170414\n",
      "35000 [46.07389914  4.12459285] 46.658879288166574\n",
      "36000 [46.18828702  4.10347025] 46.523428753414635\n",
      "37000 [46.29137798  4.08443372] 46.41341122965379\n",
      "38000 [46.3842877   4.06727723] 46.3240512610374\n",
      "39000 [46.46802168  4.05181511] 46.25147006016929\n",
      "40000 [46.54348611  4.03788002] 46.192517144215635\n",
      "41000 [46.61149769  4.02532116] 46.144633584039255\n",
      "42000 [46.67279246  4.01400262] 46.10574093050256\n",
      "43000 [46.72803378  4.00380188] 46.07415099663893\n",
      "44000 [46.77781947  3.99460857] 46.04849257966917\n",
      "45000 [46.82268834  3.98632319] 46.02765194213451\n",
      "46000 [46.86312598  3.97885608] 46.01072446865233\n",
      "47000 [46.89957     3.97212641] 45.99697539989117\n",
      "48000 [46.93241482  3.96606136] 45.985807939372165\n",
      "48023 [46.93313079  3.96592915] 45.985577422762795\n"
     ]
    }
   ],
   "source": [
    "W = np.array([1, 0.5])\n",
    "delta = 1e-5\n",
    "err_prev = 0\n",
    "i = 0\n",
    "\n",
    "while True:\n",
    "    y_pred = np.dot(W, X)\n",
    "    err = calc_mse(y, y_pred)\n",
    "    W -= alpha * 1/n * 2 * (X @ (y_pred - y))\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(i, W, err)\n",
    "        \n",
    "    if abs(err_prev - err) <= delta:\n",
    "        print(i, W, err)\n",
    "        break\n",
    "    else:\n",
    "        err_prev = err\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
